{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy\n",
    "from PIL import Image\n",
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "import pytesseract\n",
    "import difflib\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_folder = \"./images\"\n",
    "text_folder = \"./source\"\n",
    "images = [\"sample01.png\", \"sample02.png\"]\n",
    "texts = [\"sample01.txt\", \"sample02.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(actual, expected, print_score=True):\n",
    "    s = difflib.SequenceMatcher(None, actual, expected)\n",
    "    if print_score:\n",
    "        print(\"{:.5f}\".format(s.ratio()))\n",
    "    # print(s.get_matching_blocks())\n",
    "    return s.ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Image with OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNG RGBA\n",
      "Parking: You may park anywhere on the ce\n",
      "king. Keep in mind the carpool hours and park\n",
      "afternoon\n",
      "\n",
      "Under School Age Children:While we love\n",
      "inappropriate to have them on campus @ )\n",
      "that they may be invited or can accompany :\n",
      "you adhere to our _ policy for the benefit of\n",
      "\n",
      " \n",
      "\f",
      "\n",
      "0.42293\n",
      "PNG LA\n",
      "Sonnet for Lena\n",
      "\n",
      " \n",
      "\f",
      "\n",
      "0.05207\n"
     ]
    }
   ],
   "source": [
    "for idx, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_folder, image_name))\n",
    "    print(image.format, image.mode)\n",
    "    image = image.convert(\"RGB\")\n",
    "    result = pytesseract.image_to_string(image)\n",
    "\n",
    "    with open(os.path.join(text_folder, texts[idx]), 'r') as f:\n",
    "            base_text = f.readlines()\n",
    "            base_text = \"\".join(base_text)\n",
    "            # base_text = [line.strip() for line in base_text]\n",
    "\n",
    "\n",
    "    print(result)\n",
    "    evaluate(result, base_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_image(image_np, threshold=0, op = '<'):\n",
    "    # Set pixels with value less than threshold to 0, otherwise set is as 255\n",
    "    if op == '<':\n",
    "        image_result_np = np.where(image_np < threshold, 0, 1)\n",
    "    else:\n",
    "        image_result_np = np.where(image_np > threshold, 0, 1)\n",
    "    # Convert numpy array back to PIL image object\n",
    "    image_result = Image.fromarray((image_result_np * 255).astype(np.uint8))\n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_thresholding_in(image, max_value=255):\n",
    "    # Image must be in grayscale\n",
    "    image_np = np.array(image)\n",
    "    # Set total number of bins in the histogram\n",
    "    number_of_bins = 256  # Since our image is 8 bits, we used 256 for now\n",
    "    # Get the image histogram\n",
    "    histogram, bin_edges = np.histogram(image_np, bins=number_of_bins)\n",
    "\n",
    "    # Calculate centers of bins\n",
    "    bin_center = (bin_edges[:-1] + bin_edges[1:]) / 2.\n",
    "    # Iterate over all thresholds (indices) and get the probabilities \\w_0(t), \\w_1(t)\n",
    "    w_0 = np.cumsum(histogram)\n",
    "    w_1 = np.cumsum(histogram[::-1])[::-1]\n",
    "\n",
    "    # Get the class means \\mu0(t)\n",
    "    m_0 = np.cumsum(histogram * bin_center) / w_0\n",
    "    # Get the class means \\mu1(t)\n",
    "    m_1 = (np.cumsum((histogram * bin_center)[::-1]) / w_1[::-1])[::-1]\n",
    "\n",
    "    # Calculate the inter-class variance\n",
    "    inter_var = w_0[:-1] * w_1[1:] * (m_0[:-1] - m_1[1:]) ** 2\n",
    "\n",
    "    # Minimize intra-class variance, which is equal to maximize the inter_class_variance function val\n",
    "    max_val_index = np.argmax(inter_var)\n",
    "\n",
    "    # Get the threshold value\n",
    "    thresh = bin_center[:-1][max_val_index]\n",
    "    # Get the image by performing the thresholding\n",
    "    image_result = threshold_image(image_np, thresh)\n",
    "\n",
    "    return image_result, thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otsu thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41019\n",
      "0.03374\n"
     ]
    }
   ],
   "source": [
    "for idx, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_folder, image_name))\n",
    "    # print(image.format, image.mode)\n",
    "    image = image.convert(\"L\")\n",
    "\n",
    "    with open(os.path.join(text_folder, texts[idx]), 'r') as f:\n",
    "            base_text = f.readlines()\n",
    "            base_text = \"\".join(base_text)\n",
    "            # base_text = [line.strip() for line in base_text]\n",
    "    img_cv = numpy.array(image)\n",
    "    ret, image_th_cv = cv.threshold(img_cv, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    image_th = Image.fromarray(image_th_cv)\n",
    "    result_th = pytesseract.image_to_string(image_th)\n",
    "    image_th.show()\n",
    "\n",
    "    evaluate(result_th, base_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self implementation of Otsu thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold pixel value=125.314453125\n",
      "0.41019\n",
      "Threshold pixel value=141.1875\n",
      "0.03374\n"
     ]
    }
   ],
   "source": [
    "for idx, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_folder, image_name))\n",
    "    # print(image.format, image.mode)\n",
    "    image = image.convert(\"L\")\n",
    "\n",
    "    with open(os.path.join(text_folder, texts[idx]), 'r') as f:\n",
    "            base_text = f.readlines()\n",
    "            base_text = \"\".join(base_text)\n",
    "            # base_text = [line.strip() for line in base_text]\n",
    "\n",
    "    image_th, thresh = otsu_thresholding_in(image)\n",
    "    print(f\"Threshold pixel value={thresh}\")\n",
    "    image_th.show()\n",
    "    result_th = pytesseract.image_to_string(image_th)\n",
    "    \n",
    "\n",
    "    evaluate(result_th, base_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/29731726/how-to-calculate-a-gaussian-kernel-matrix-efficiently-in-numpy\n",
    "def gaussian_kernel(kernel_size=7, std=1, normalize=True):\n",
    "    gaussian_kernel_1d = scipy.signal.gaussian(kernel_size, std=std).reshape(kernel_size, 1)\n",
    "    gaussian_kernel_2d = np.outer(gaussian_kernel_1d, gaussian_kernel_1d)\n",
    "    if normalize:\n",
    "        return gaussian_kernel_2d / gaussian_kernel_2d.sum()\n",
    "    else:\n",
    "        return gaussian_kernel_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.mathworks.com/matlabcentral/fileexchange/8647-local-adaptive-thresholding\n",
    "# https://homepages.inf.ed.ac.uk/rbf/HIPR2/adpthrsh.htm\n",
    "def adaptive_gaussian_thresholding_in(image, max_value=255, block_size=7, C=0, std=1):\n",
    "    # Image must be in grayscale\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    kernel = gaussian_kernel(block_size, std=std)\n",
    "    # print(f\"kernel={kernel}\")\n",
    "\n",
    "    image_convolved_np = scipy.signal.convolve2d(image_np, kernel, mode='same', boundary='symm')\n",
    "    image_result_np = image_convolved_np - image_np - C\n",
    "    # print(image_result_np)\n",
    "\n",
    "    image_result = threshold_image(image_result_np, op='>')\n",
    "\n",
    "    return image_result\n",
    "\n",
    "\n",
    "# https://www.mathworks.com/matlabcentral/fileexchange/8647-local-adaptive-thresholding\n",
    "def adaptive_mean_thresholding_in(image, max_value=255, block_size=7, C=0):\n",
    "    # Image must be in grayscale\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    kernel = np.ones((block_size, block_size)) / (block_size ** 2)\n",
    "    image_convolved_np = scipy.signal.convolve2d(image_np, kernel, mode='same', boundary='symm')\n",
    "    image_result_np = image_convolved_np - image_np - C\n",
    "    image_result = threshold_image(image_result_np, op='>')\n",
    "\n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07511361 0.1238414  0.07511361]\n",
      " [0.1238414  0.20417996 0.1238414 ]\n",
      " [0.07511361 0.1238414  0.07511361]]\n"
     ]
    }
   ],
   "source": [
    "print(gaussian_kernel(3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Adaptive Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive gaussian:\n",
      "0.98935\n",
      "Adaptive gaussian:\n",
      "0.12692\n"
     ]
    }
   ],
   "source": [
    "for idx, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_folder, image_name))\n",
    "    # print(image.format, image.mode)\n",
    "    image = image.convert(\"L\")\n",
    "\n",
    "    with open(os.path.join(text_folder, texts[idx]), 'r') as f:\n",
    "            base_text = f.readlines()\n",
    "            base_text = \"\".join(base_text)\n",
    "            # base_text = [line.strip() for line in base_text]\n",
    "    img_cv = numpy.array(image)\n",
    "    img_th_cv = cv.adaptiveThreshold(img_cv, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, \\\n",
    "                              cv.THRESH_BINARY, 11, 8)\n",
    "    \n",
    "    image_adaptive_gaussian = Image.fromarray(img_th_cv)\n",
    "    # image_adaptive_gaussian.show()\n",
    "    result_adaptive_gaussian = pytesseract.image_to_string(image_adaptive_gaussian)\n",
    "    # print(result_adaptive_gaussian)\n",
    "\n",
    "    print(\"Adaptive gaussian:\")\n",
    "    evaluate(result_adaptive_gaussian, base_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self implementation of Adaptive Gaussian thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99225\n",
      "0.01475\n"
     ]
    }
   ],
   "source": [
    "for idx, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_folder, image_name))\n",
    "    # print(image.format, image.mode)\n",
    "    image = image.convert(\"L\")\n",
    "\n",
    "    with open(os.path.join(text_folder, texts[idx]), 'r') as f:\n",
    "            base_text = f.readlines()\n",
    "            base_text = \"\".join(base_text)\n",
    "            # base_text = [line.strip() for line in base_text]\n",
    "\n",
    "    image_th = adaptive_gaussian_thresholding_in(image, block_size=11, std=2, C=8)\n",
    "    image_th.show()\n",
    "    result_th = pytesseract.image_to_string(image_th)\n",
    "    \n",
    "\n",
    "    evaluate(result_th, base_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found better accuracy of 0.0037593984962406013 for image sample01.png with parameters 3 1 0\n",
      "Found better accuracy of 0.007366482504604052 for image sample01.png with parameters 7 2 0\n",
      "Found better accuracy of 0.017152658662092625 for image sample01.png with parameters 9 1 0\n",
      "Found better accuracy of 0.3133004926108374 for image sample01.png with parameters 3 1 2\n",
      "Found better accuracy of 0.3192389006342495 for image sample01.png with parameters 3 2 2\n",
      "Found better accuracy of 0.6883365200764818 for image sample01.png with parameters 3 1 3\n",
      "Found better accuracy of 0.8460076045627376 for image sample01.png with parameters 7 1 3\n",
      "Found better accuracy of 0.8525214081826832 for image sample01.png with parameters 9 1 3\n",
      "Found better accuracy of 0.9198473282442748 for image sample01.png with parameters 5 2 4\n",
      "Found better accuracy of 0.9244186046511628 for image sample01.png with parameters 5 1 5\n",
      "Found better accuracy of 0.9282945736434108 for image sample01.png with parameters 7 1 5\n",
      "Found better accuracy of 0.9855351976856316 for image sample01.png with parameters 11 2 5\n",
      "Found better accuracy of 0.9903100775193798 for image sample01.png with parameters 7 1 6\n",
      "Found better accuracy of 0.9922480620155039 for image sample01.png with parameters 11 2 8\n",
      "Found better accuracy of 0.05891016200294551 for image sample02.png with parameters 7 1 2\n",
      "Found better accuracy of 0.07470651013874066 for image sample02.png with parameters 7 2 2\n",
      "Found better accuracy of 0.12580645161290321 for image sample02.png with parameters 9 2 2\n",
      "Found better accuracy of 0.29385574354407834 for image sample02.png with parameters 9 2 4\n",
      "[0.9922480620155039, 0.29385574354407834]\n",
      "[11, 9]\n",
      "[2, 2]\n",
      "[8, 4]\n"
     ]
    }
   ],
   "source": [
    "# Parameters fine-tuning\n",
    "accuracy = [0,0]\n",
    "block_size_optimum = [0,0]\n",
    "std_optimum = [0,0]\n",
    "C_optimum = [0,0]\n",
    "for idx, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_folder, image_name))\n",
    "    # print(image.format, image.mode)\n",
    "    image = image.convert(\"L\")\n",
    "\n",
    "    with open(os.path.join(text_folder, texts[idx]), 'r') as f:\n",
    "            base_text = f.readlines()\n",
    "            base_text = \"\".join(base_text)\n",
    "            # base_text = [line.strip() for line in base_text]\n",
    "    for C in range(0,10):\n",
    "        for block_size in range(3,13,2):\n",
    "            for std in range(1,3):\n",
    "                image_th = adaptive_gaussian_thresholding_in(image, block_size=block_size,std=std,C=C)\n",
    "                # image_th.show()\n",
    "                result_th = pytesseract.image_to_string(image_th)\n",
    "                score = evaluate(result_th, base_text,False)\n",
    "                if accuracy[idx] < score:\n",
    "                    print(f\"Found better accuracy of {score} for image {image_name} with parameters {block_size} {std} {C}\")\n",
    "                    accuracy[idx] = score\n",
    "                    block_size_optimum[idx] = block_size\n",
    "                    std_optimum[idx] = std\n",
    "                    C_optimum[idx] = C\n",
    "                # print(f\"{block_size} | {std} | {C} | {score:.5f}\")\n",
    "print(accuracy)\n",
    "print(block_size_optimum)\n",
    "print(std_optimum)\n",
    "print(C_optimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur_in(image, kernel_size=7, std=1):\n",
    "    image_np = np.array(image)\n",
    "    kernel = gaussian_kernel(kernel_size=kernel_size, std=std)\n",
    "    image_convolved_np = scipy.signal.convolve2d(image_np, kernel, mode='same', boundary='symm')\n",
    "    return Image.fromarray(image_convolved_np)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gaussian Blur + Adaptive Gaussian Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian blur (3,3) + Adaptive gaussian for sample02.png score: 0.18039\n",
      "Gaussian blur (5,5) + Adaptive gaussian for sample02.png score: 0.31348\n",
      "Gaussian blur (7,7) + Adaptive gaussian for sample02.png score: 0.07231\n",
      "Gaussian blur (9,9) + Adaptive gaussian for sample02.png score: 0.13596\n",
      "Gaussian blur (11,11) + Adaptive gaussian for sample02.png score: 0.07710\n",
      "Gaussian blur (13,13) + Adaptive gaussian for sample02.png score: 0.06115\n",
      "Gaussian blur (15,15) + Adaptive gaussian for sample02.png score: 0.05722\n"
     ]
    }
   ],
   "source": [
    "for kernel_size in range(3,17,2):\n",
    "        image = Image.open(os.path.join(image_folder, image_name))\n",
    "        # print(image.format, image.mode)\n",
    "        image = image.convert(\"L\")\n",
    "\n",
    "        with open(os.path.join(text_folder, texts[idx]), 'r') as f:\n",
    "                base_text = f.readlines()\n",
    "                base_text = \"\".join(base_text)\n",
    "                # base_text = [line.strip() for line in base_text]\n",
    "        img_cv = numpy.array(image)\n",
    "        img_blur = cv.GaussianBlur(img_cv, (kernel_size, kernel_size), 0)\n",
    "#         img_th_cv = cv.adaptiveThreshold(img_blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, \\\n",
    "#                                   cv.THRESH_BINARY, 11, 8)\n",
    "        image_th = adaptive_gaussian_thresholding_in(img_blur, block_size=9, std=2, C=4)\n",
    "        # image_th.show()\n",
    "        result_th = pytesseract.image_to_string(image_th)\n",
    "        score = evaluate(result_th, base_text, print_score=False)\n",
    "        print(f\"Gaussian blur ({kernel_size},{kernel_size}) + Adaptive gaussian for {image_name} score: {score:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found better accuracy of 0.9806576402321083 for image sample01.png with parameters 3 0.5\n",
      "Found better accuracy of 0.9912536443148688 for image sample01.png with parameters 3 1\n",
      "Found better accuracy of 0.07668231611893583 for image sample02.png with parameters 3 0.5\n",
      "Found better accuracy of 0.5845674201091192 for image sample02.png with parameters 3 1\n"
     ]
    }
   ],
   "source": [
    "accuracy = [0,0]\n",
    "kernel_size_optimum = [0,0]\n",
    "std_optimum = [0,0]\n",
    "for idx, image_name in enumerate(images):\n",
    "    for kernel_size in range(3,17,2):\n",
    "        for std in [0.5,1,2]:\n",
    "            image = Image.open(os.path.join(image_folder, image_name))\n",
    "            # print(image.format, image.mode)\n",
    "            image = image.convert(\"L\")\n",
    "\n",
    "            with open(os.path.join(text_folder, texts[idx]), 'r') as f:\n",
    "                    base_text = f.readlines()\n",
    "                    base_text = \"\".join(base_text)\n",
    "                    # base_text = [line.strip() for line in base_text]\n",
    "            image = gaussian_blur_in(image, kernel_size=kernel_size, std=std)\n",
    "            image_th = adaptive_gaussian_thresholding_in(image, block_size=15, std=2, C=4)\n",
    "            # image_th.show()\n",
    "            result_th = pytesseract.image_to_string(image_th)\n",
    "            score = evaluate(result_th, base_text, print_score=False)\n",
    "            if accuracy[idx] < score:\n",
    "                print(f\"Found better accuracy of {score} for image {image_name} with parameters {kernel_size} {std}\")\n",
    "                accuracy[idx] = score\n",
    "                kernel_size_optimum[idx] = kernel_size\n",
    "                std_optimum[idx] = std\n",
    "            # print(f\"Gaussian blur ({kernel_size},{kernel_size}) std={std} + Adaptive gaussian for {image_name} score: {score:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9912536443148688, 0.5845674201091192]\n",
      "[3, 3]\n",
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "print(kernel_size_optimum)\n",
    "print(std_optimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian blur + Adaptive gaussian for sample01.png score: 0.99516\n",
      "Parking: You may park anywhere on the campus where there are no signs prohibiting par-\n",
      "king. Keep in mind the carpool hours and park accordingly so you do not get blocked in the\n",
      "afternoon\n",
      "\n",
      "Under School Age Children:While we love the younger children, it can be disruptive and\n",
      "inappropriate to have them on campus during school hours. There may be special limes\n",
      "that they may be invited or can accompany a parent volunteer, but otherwise we ask that\n",
      "you adhere toour policy for the benefit of the students and staff.\n",
      "\f",
      "\n",
      "equal     result_th[0:355] --> base_text[0:355] 'Parking: You may park anywhere on the campus where there are no signs prohibiting par-\\nking. Keep in mind the carpool hours and park accordingly so you do not get blocked in the\\nafternoon\\n\\nUnder School Age Children:While we love the younger children, it can be disruptive and\\ninappropriate to have them on campus during school hours. There may be special ' --> 'Parking: You may park anywhere on the campus where there are no signs prohibiting par-\\nking. Keep in mind the carpool hours and park accordingly so you do not get blocked in the\\nafternoon\\n\\nUnder School Age Children:While we love the younger children, it can be disruptive and\\ninappropriate to have them on campus during school hours. There may be special '\n",
      "replace   result_th[355:356] --> base_text[355:356]      'l' --> 't'\n",
      "equal     result_th[356:462] --> base_text[356:462] 'imes\\nthat they may be invited or can accompany a parent volunteer, but otherwise we ask that\\nyou adhere to' --> 'imes\\nthat they may be invited or can accompany a parent volunteer, but otherwise we ask that\\nyou adhere to'\n",
      "insert    result_th[462:462] --> base_text[462:463]       '' --> ' '\n",
      "equal     result_th[462:515] --> base_text[463:516] 'our policy for the benefit of the students and staff.' --> 'our policy for the benefit of the students and staff.'\n",
      "delete    result_th[515:517] --> base_text[516:516] '\\n\\x0c' --> ''\n",
      "Gaussian blur + Adaptive gaussian for sample02.png score: 0.58457\n",
      "Sonnet for Lena\n",
      "\n",
      "OQ dear Lena, your beauty ix su vast\n",
      "\n",
      "It is bard sometimes to deseribe it fast.\n",
      "Tthonglit the entire world | would impress\n",
      "If only your portrait [ could compress,\n",
      "\n",
      "Alas! First when [tried to use VQ\n",
      "\n",
      "1 found that your cheeks belong to only you.\n",
      "Your silky hair contains n thousand lines\n",
      "Hard ta mates with sums of discrete cosines.\n",
      "And for your lips, sensual and tactual\n",
      "Hirteen Crays fonnd not the proper fractal,\n",
      "ryernie\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "And while these setbacks are all quite\n",
      "Tinisgit bave fixed thet with hacks here or there\n",
      "Bat when filters took sparkle from yon eyes\n",
      "Teaidl, Datne all this, PM juse digitize.”\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Pietins Cailthacrst\n",
      "\f",
      "\n",
      "equal     result_th[0:18] --> base_text[0:18] 'Sonnet for Lena\\n\\nO' --> 'Sonnet for Lena\\n\\nO'\n",
      "delete    result_th[18:19] --> base_text[18:18]      'Q' --> ''\n",
      "equal     result_th[19:44] --> base_text[18:43] ' dear Lena, your beauty i' --> ' dear Lena, your beauty i'\n",
      "replace   result_th[44:48] --> base_text[43:47]   'x su' --> 's so'\n",
      "equal     result_th[48:54] --> base_text[47:53] ' vast\\n' --> ' vast\\n'\n",
      "replace   result_th[54:61] --> base_text[53:83] '\\nIt is ' --> 'It is hard sometimes to descri'\n",
      "equal     result_th[61:62] --> base_text[83:84]      'b' --> 'b'\n",
      "delete    result_th[62:86] --> base_text[84:84] 'ard sometimes to deserib' --> ''\n",
      "equal     result_th[86:97] --> base_text[84:95] 'e it fast.\\n' --> 'e it fast.\\n'\n",
      "replace   result_th[97:102] --> base_text[95:101]  'Tthon' --> 'I thou'\n",
      "equal     result_th[102:103] --> base_text[101:102]      'g' --> 'g'\n",
      "replace   result_th[103:105] --> base_text[102:103]     'li' --> 'h'\n",
      "equal     result_th[105:124] --> base_text[103:122] 't the entire world ' --> 't the entire world '\n",
      "replace   result_th[124:125] --> base_text[122:123]      '|' --> 'I'\n",
      "equal     result_th[125:162] --> base_text[123:160] ' would impress\\nIf only your portrait ' --> ' would impress\\nIf only your portrait '\n",
      "replace   result_th[162:163] --> base_text[160:161]      '[' --> 'I'\n",
      "equal     result_th[163:178] --> base_text[161:176] ' could compress' --> ' could compress'\n",
      "replace   result_th[178:180] --> base_text[176:177]    ',\\n' --> '.'\n",
      "equal     result_th[180:198] --> base_text[177:195] '\\nAlas! First when ' --> '\\nAlas! First when '\n",
      "replace   result_th[198:199] --> base_text[195:197]      '[' --> 'I '\n",
      "equal     result_th[199:215] --> base_text[197:213] 'tried to use VQ\\n' --> 'tried to use VQ\\n'\n",
      "replace   result_th[215:217] --> base_text[213:214]    '\\n1' --> 'I'\n",
      "equal     result_th[217:286] --> base_text[214:283] ' found that your cheeks belong to only you.\\nYour silky hair contains ' --> ' found that your cheeks belong to only you.\\nYour silky hair contains '\n",
      "replace   result_th[286:287] --> base_text[283:284]      'n' --> 'a'\n",
      "equal     result_th[287:309] --> base_text[284:306] ' thousand lines\\nHard t' --> ' thousand lines\\nHard t'\n",
      "replace   result_th[309:316] --> base_text[306:313] 'a mates' --> 'o match'\n",
      "equal     result_th[316:387] --> base_text[313:384] ' with sums of discrete cosines.\\nAnd for your lips, sensual and tactual\\n' --> ' with sums of discrete cosines.\\nAnd for your lips, sensual and tactual\\n'\n",
      "replace   result_th[387:388] --> base_text[384:386]      'H' --> 'Th'\n",
      "equal     result_th[388:403] --> base_text[386:401] 'irteen Crays fo' --> 'irteen Crays fo'\n",
      "replace   result_th[403:404] --> base_text[401:402]      'n' --> 'u'\n",
      "equal     result_th[404:429] --> base_text[402:427] 'nd not the proper fractal' --> 'nd not the proper fractal'\n",
      "insert    result_th[429:429] --> base_text[427:575]       '' --> '.\\nAnd while these setbacks are all quite severe\\nI might have fixed them with hacks here or there\\nBut when filters took sparkle from your eyes\\nI said'\n",
      "equal     result_th[429:430] --> base_text[575:576]      ',' --> ','\n",
      "replace   result_th[430:484] --> base_text[576:615] '\\nryernie\\n\\n \\n\\n \\n\\nAnd while these setbacks are all quite' --> \" 'Damn all this.  I'll just digitize.'\\n\"\n",
      "equal     result_th[484:486] --> base_text[615:617]    '\\nT' --> '\\nT'\n",
      "replace   result_th[486:635] --> base_text[617:621] 'inisgit bave fixed thet with hacks here or there\\nBat when filters took sparkle from yon eyes\\nTeaidl, Datne all this, PM juse digitize.”\\n\\n \\n\\n \\n\\nPietin' --> 'homa'\n",
      "equal     result_th[635:638] --> base_text[621:624]    's C' --> 's C'\n",
      "replace   result_th[638:650] --> base_text[624:633] 'ailthacrst\\n\\x0c' --> 'olthrust\\n'\n"
     ]
    }
   ],
   "source": [
    "for idx, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_folder, image_name))\n",
    "    # print(image.format, image.mode)\n",
    "    image = image.convert(\"L\")\n",
    "\n",
    "    with open(os.path.join(text_folder, texts[idx]), 'r') as f:\n",
    "            base_text = f.readlines()\n",
    "            base_text = \"\".join(base_text)\n",
    "            # base_text = [line.strip() for line in base_text]\n",
    "    image = gaussian_blur_in(image, kernel_size=3, std=1)\n",
    "    image_th = adaptive_gaussian_thresholding_in(image, block_size=9, std=2, C=4)\n",
    "    image_th.show()\n",
    "    result_th = pytesseract.image_to_string(image_th)\n",
    "    score = evaluate(result_th, base_text, print_score=False)\n",
    "    print(f\"Gaussian blur + Adaptive gaussian for {image_name} score: {score:.5f}\")\n",
    "    print(result_th)\n",
    "    s = difflib.SequenceMatcher(None, result_th, base_text)\n",
    "    for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "        print('{:7}   result_th[{}:{}] --> base_text[{}:{}] {!r:>8} --> {!r}'.format(\n",
    "            tag, i1, i2, j1, j2, result_th[i1:i2], base_text[j1:j2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}